{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from recommender import recommender\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import creds  # Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import each playlist representing a specific mood\n",
    "drake_sad = pd.read_csv('playlist_1.csv')\n",
    "drake_hype = pd.read_csv('playlist_2.csv')\n",
    "drake_chill = pd.read_csv('playlist_3.csv')\n",
    "drake_romantic = pd.read_csv('playlist_4.csv')\n",
    "drake_party = pd.read_csv('playlist_5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps to Evalutate Recommendation system:\n",
    "1. Split data into train and test\n",
    "2. Run the recommendations on each song in the playlist, add recommendations to a recommendation list\n",
    "3. Check if the recommendations are accurate with the test data\n",
    "4. Compute metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to split the dataset into training and testing\n",
    "def split_dataset(df, train_ratio=0.7):\n",
    "    num_rows = len(df)\n",
    "    num_train = int(num_rows * train_ratio)\n",
    "    \n",
    "    # Shuffle the DataFrame rows\n",
    "    shuffled_df = df.sample(frac=1, random_state=42)\n",
    "    \n",
    "    # Split into training and testing DataFrames\n",
    "    train_df = shuffled_df.iloc[:num_train]\n",
    "    test_df = shuffled_df.iloc[num_train:]\n",
    "    \n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "sad_train, sad_test = split_dataset(drake_sad)\n",
    "hype_train, hype_test = split_dataset(drake_hype)\n",
    "chill_train, chill_test = split_dataset(drake_chill)\n",
    "romantic_train, romantic_test = split_dataset(drake_romantic)\n",
    "party_train, party_test = split_dataset(drake_party)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = 'drake_songs_dataset.csv'\n",
    "\n",
    "#Read in data as a dataframe\n",
    "drake_df = pd.read_csv(DATASET_NAME)\n",
    "\n",
    "#Get desired audio features\n",
    "selected_features = [\n",
    "    'danceability', 'energy', 'key', 'loudness',\n",
    "    'speechiness', 'acousticness', 'instrumentalness', \n",
    "    'liveness', 'valence', 'tempo'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scales all data before computing cosine similarity matrix\n",
    "def scale_data(input_song, drake_df):\n",
    "    # Making a copy to not alter drake_df\n",
    "    recommender_dataset = drake_df.copy()\n",
    "    \n",
    "    # Removing input song from recommender_dataset so it isn't recommended\n",
    "    recommender_dataset = recommender_dataset[recommender_dataset['track_uri'] != input_song['track_uri']]\n",
    "\n",
    "    #Getting only necessary columns before concat\n",
    "    recommender_dataset = recommender_dataset[selected_features].copy()\n",
    "    input_song = input_song[selected_features].copy().to_frame().T\n",
    "    \n",
    "    #Combining rows for features scaling\n",
    "    all_features = pd.concat([input_song, recommender_dataset])\n",
    "    scaler = StandardScaler()\n",
    "    all_features_scaled = scaler.fit_transform(all_features)\n",
    "\n",
    "    user_features = all_features_scaled[:1, :].copy()\n",
    "    dataset_features = all_features_scaled[1:, :].copy()\n",
    "    \n",
    "    return user_features, dataset_features\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that runs the recommendation system\n",
    "def make_recs(input_song_index, playlist_df, drake_df):\n",
    "    #Keeps all columns so that we can extract the recommended song names and artists later\n",
    "    df_all_cols = drake_df.copy()\n",
    "\n",
    "    # Get the input song that we will make recommendations from\n",
    "    input_song = playlist_df.iloc[input_song_index]\n",
    "\n",
    "    #Remove the user's inputted track from original dataset so it isn't recommended later on\n",
    "    drake_df =  drake_df[drake_df['track_uri'] != input_song['track_uri']]\n",
    "\n",
    "    #Scale data\n",
    "    user_features, dataset_features = scale_data(input_song, drake_df)\n",
    "\n",
    "    # Recommending system\n",
    "    return recommender(user_features, dataset_features, df_all_cols, 5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(recommended_songs, test_songs):\n",
    "    # Convert the recommended and test songs to sets for efficient comparison\n",
    "    recommended_set = set(recommended_songs)\n",
    "    test_set = set(test_songs)\n",
    "    \n",
    "    # Count the number of correct recommendations (intersection of sets)\n",
    "    num_correct_recommendations = len(recommended_set & test_set)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = num_correct_recommendations / len(test_set)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def calculate_precision(recommended_songs, test_songs):\n",
    "    recommended_set = set(recommended_songs)\n",
    "    test_set = set(test_songs)\n",
    "    \n",
    "    true_positives = len(recommended_set & test_set)\n",
    "    false_positives = len(recommended_set - test_set)\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    return precision\n",
    "\n",
    "def calculate_recall(recommended_songs, test_songs):\n",
    "    recommended_set = set(recommended_songs)\n",
    "    test_set = set(test_songs)\n",
    "    \n",
    "    true_positives = len(recommended_set & test_set)\n",
    "    false_negatives = len(test_set - recommended_set)\n",
    "    \n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    return recall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playlist 1\n",
      "-------------------\n",
      "Accuracy: 0.55\n",
      "Precision: 0.05\n",
      "Recall: 0.55\n",
      "-------------------\n",
      "Playlist 2\n",
      "-------------------\n",
      "Accuracy: 0.56\n",
      "Precision: 0.08\n",
      "Recall: 0.56\n",
      "-------------------\n",
      "Playlist 3\n",
      "-------------------\n",
      "Accuracy: 0.69\n",
      "Precision: 0.16\n",
      "Recall: 0.69\n",
      "-------------------\n",
      "Playlist 4\n",
      "-------------------\n",
      "Accuracy: 0.75\n",
      "Precision: 0.22\n",
      "Recall: 0.75\n",
      "-------------------\n",
      "Playlist 5\n",
      "-------------------\n",
      "Accuracy: 0.74\n",
      "Precision: 0.26\n",
      "Recall: 0.74\n",
      "-------------------\n",
      "Mean Accuracy: 0.658\n",
      "Mean Precision: 0.658\n",
      "Mean Recall: 0.658\n"
     ]
    }
   ],
   "source": [
    "NUM_PLAYLISTS = 5\n",
    "\n",
    "# List of playlists (dataframes) to test recommendation performance on\n",
    "playlist_list = [drake_sad, drake_hype, drake_chill, drake_romantic, drake_party]\n",
    "\n",
    "#Empty lists to calculate average metrics later\n",
    "accuracy_sum = 0\n",
    "precision_sum = 0\n",
    "recall_sum = 0\n",
    "\n",
    "# Run the recommendation system on every song in the list for each playlist\n",
    "for j, playlist in enumerate(playlist_list):\n",
    "    #Splitting into training and testing data\n",
    "    training_data, testing_data = split_dataset(playlist)\n",
    "\n",
    "    # Create empty list to store recommendations\n",
    "    recommendations = []\n",
    "\n",
    "    # Running recommendation system\n",
    "    for i, row in playlist.iterrows():\n",
    "        recommendations += make_recs(i, playlist, drake_df)['track_name'].to_list()\n",
    "\n",
    "    # Outputting accuracy for playlist\n",
    "    print(f\"Playlist {j + 1}\")\n",
    "    print(\"-------------------\")    \n",
    "    print(f\"Accuracy: {round(calculate_accuracy(recommendations, testing_data['track_name']),2 )}\\nPrecision: {round(calculate_precision(recommendations, testing_data['track_name']), 2)}\\nRecall: {round(calculate_recall(recommendations, testing_data['track_name']), 2)}\")\n",
    "    print(\"-------------------\")    \n",
    "\n",
    "    #Storing metrics for later\n",
    "    accuracy_sum += round(calculate_accuracy(recommendations, testing_data['track_name']), 2)\n",
    "    precision_sum += round(calculate_accuracy(recommendations, testing_data['track_name']), 2)\n",
    "    recall_sum += round(calculate_accuracy(recommendations, testing_data['track_name']), 2)\n",
    "\n",
    "# Aggregate metrics\n",
    "print(f\"Mean Accuracy: {accuracy_sum / NUM_PLAYLISTS}\")\n",
    "print(f\"Mean Precision: {precision_sum / NUM_PLAYLISTS}\")\n",
    "print(f\"Mean Recall: {recall_sum / NUM_PLAYLISTS}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
